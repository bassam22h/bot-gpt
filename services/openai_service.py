import re
import logging
import os
import asyncio
from openai import AsyncOpenAI

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot_errors.log'),
        logging.StreamHandler()
    ]
)

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙØªØ§Ø­ API Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
API_KEY = os.getenv('OPENROUTER_API_KEY')
if not API_KEY:
    logging.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ OPENROUTER_API_KEY ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©")

aclient = AsyncOpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=API_KEY,
)

async def generate_post(user_input, platform, max_retries=3):
    """Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©"""
    config = {
        "ØªÙˆÙŠØªØ±": {
            "model": "deepseek/deepseek-v3-base:free",
            "max_tokens": 300,
            "template": """
            ğŸŒŸ {input}\n
            - Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
            - Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
            - Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©
            #Ù‡Ø§Ø´ØªØ§Ù‚1 #Ù‡Ø§Ø´ØªØ§Ù‚2
            """
        },
        "Ù„ÙŠÙ†ÙƒØ¯Ø¥Ù†": {
            "model": "meta-llama/llama-3-70b-instruct:nitro",
            "max_tokens": 500,
            "template": """
            ğŸš€ {input}\n\n
            1. Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø£ÙˆÙ„
            2. Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø«Ø§Ù†ÙŠ
            3. Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø«Ø§Ù„Ø«\n\n
            #Ù‡Ø§Ø´ØªØ§Ù‚1 #Ù‡Ø§Ø´ØªØ§Ù‚2 #Ù‡Ø§Ø´ØªØ§Ù‚3
            """
        }
    }

    if not API_KEY:
        return "âš ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©. ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©."

    if platform not in config:
        return "âš ï¸ Ø§Ù„Ù…Ù†ØµØ© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©. Ø§Ø®ØªØ±: ØªÙˆÙŠØªØ± Ø£Ùˆ Ù„ÙŠÙ†ÙƒØ¯Ø¥Ù†"

    for attempt in range(max_retries):
        try:
            response = await aclient.chat.completions.create(
                model=config[platform]["model"],
                messages=[
                    {"role": "system", "content": config[platform]["template"]},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.7,
                max_tokens=config[platform]["max_tokens"],
                timeout=30.0
            )

            if not response.choices:
                raise ValueError("Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙØ§Ø±ØºØ© Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù…")

            content = response.choices[0].message.content
            return self._clean_content(content)

        except Exception as e:
            logging.error(f"Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt+1} ÙØ´Ù„Øª: {str(e)}")
            if attempt < max_retries - 1:
                await asyncio.sleep(2)
    
    return "âš ï¸ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù†Ø´ÙˆØ±. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹."

def _clean_content(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©"""
    # ... (Ù†ÙØ³ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
    return cleaned_text
